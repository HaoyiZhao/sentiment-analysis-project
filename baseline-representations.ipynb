{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert datasets into binary and frequency bag of words representations\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import random\n",
    "from collections import Counter\n",
    "import sklearn.metrics\n",
    "import sklearn.naive_bayes\n",
    "import sklearn.tree\n",
    "import sklearn.svm\n",
    "import warnings\n",
    "\n",
    "# read datasets from csv files, first column is review, second column is rating/sentiment \n",
    "imdb_training_data = pd.read_csv('IMDB-train.txt', sep = \"\\t\", header = None)\n",
    "imdb_validation_data = pd.read_csv('IMDB-valid.txt', sep = \"\\t\", header = None)\n",
    "imdb_test_data = pd.read_csv('IMDB-test.txt', sep = \"\\t\", header = None)\n",
    "\n",
    "yelp_training_data = pd.read_csv('yelp-train.txt', sep = \"\\t\", header = None)\n",
    "yelp_validation_data = pd.read_csv('yelp-valid.txt', sep = \"\\t\", header = None)\n",
    "yelp_test_data = pd.read_csv('yelp-test.txt', sep = \"\\t\", header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, convert datasets into binary and frequency bag of words representations\n",
    "\n",
    "# Method takes as input a review Data Frame and returns the top 10,000 words with highest frequency in the form of a tuple:\n",
    "# (top words dictionary with word as key and rank as value, top words information in format specified by pdf\n",
    "# that will be output into file)\n",
    "def find_top_words(reviews_data):\n",
    "    words = []\n",
    "    top_words = []\n",
    "    \n",
    "    for review in reviews_data[0]:\n",
    "        # preprocess by removing punctuation and <br /><br />, and converting reviews to lower case\n",
    "        words.extend(review.lower().replace('<br /><br />', ' ').translate(str.maketrans(\"\",\"\", string.punctuation)).split(' '))\n",
    "        \n",
    "    # remove empty strings from words list\n",
    "    words = list(filter(None, words))\n",
    "    \n",
    "    # Use Counter to find most 10,000 common words from word list, returned as tuple (string word, integer count)\n",
    "    top_words = Counter(words).most_common(10000)\n",
    "    \n",
    "    # First element of tuple is dictionary of most common word String as key, frequency rank (starting at index 0) as value\n",
    "    # Second element of tuple is List of Strings (1 for each top word) which consists of word, rank, and frequency delimited by tabs\n",
    "    # enumerate enumerates top_words list, so that we can assign unique ID/rank to dictionary, and output string\n",
    "    return {top_word[0]: index for index, top_word in enumerate(top_words)}, [top_word[0] + '\\t' + str(index) + '\\t' + str(top_word[1])  for index, top_word in enumerate(top_words)]\n",
    "    \n",
    "# find top words and output from training data sets\n",
    "imdb_top_words, imdb_output = find_top_words(imdb_training_data)\n",
    "yelp_top_words, yelp_output = find_top_words(yelp_training_data)\n",
    "    \n",
    "# method takes as input tuple list top_words (String word, frequency) and review data and returns array of vector representations of reviews, with a \n",
    "# 1 in the index of vector if the word at that index in top_words appears in the specific review\n",
    "def generate_binary_bag_of_words_representation(top_words, reviews_data):\n",
    "    vectors = []\n",
    "    \n",
    "    for review in reviews_data[0]:\n",
    "        # preprocess review and split into individual words\n",
    "        review_words = review.lower().replace('<br /><br />', ' ').translate(str.maketrans(\"\",\"\", string.punctuation)).split(' ')\n",
    "        # initialize vector to contain 10,000 0's\n",
    "        current_vector = [0] * 10000\n",
    "        # for each word in review, if word is in list of top words, set current_vector at index corresponding to id of top word to 1\n",
    "        for word in review_words:\n",
    "            if word in top_words:\n",
    "                current_vector[top_words[word]] = 1\n",
    "        vectors.append(current_vector)\n",
    "    return np.array(vectors)\n",
    "\n",
    "# method takes as input tuple list top_words (String word, frequency) and review data and returns array of vector representations of reviews, based on\n",
    "# frequency representation. Values of each vector will sum to 1, and each non-zero value in vector will correspond to its proportional\n",
    "# occurrence weight in the specific review (feature[id] = (#id in review)/#(all ids in review)\n",
    "def generate_frequency_bag_of_words_representation(top_words, reviews_data):\n",
    "    vectors = []\n",
    "    \n",
    "    for review in reviews_data[0]:\n",
    "        # preprocess review and split into individual words\n",
    "        review_words = review.lower().replace('<br /><br />', ' ').translate(str.maketrans(\"\",\"\", string.punctuation)).split(' ')\n",
    "        # initialize vector to contain 10,000 0's\n",
    "        current_vector = [0] * 10000\n",
    "        # for each word in review, if word is in list of top words, set current_vector at index corresponding to id of top word to 1\n",
    "        for word in review_words:\n",
    "            # if word is in top_words, increment vector at index given by word id from dictionary\n",
    "            if word in top_words:\n",
    "                current_vector[top_words[word]] += 1\n",
    "        \n",
    "        # calculate sum of all top_word frequencies in current review\n",
    "        top_words_sum = sum(current_vector)\n",
    "        \n",
    "        # if there is at least 1 top word in current review, divide all frequencies in vector by total number of top word frequencies in vector\n",
    "        # to yield proportion of given top words then add to vectors list, otherwise just add zero vector to vectors list\n",
    "        if top_words_sum > 0:\n",
    "            current_vector = np.divide(current_vector, top_words_sum)\n",
    "        vectors.append(current_vector)\n",
    "    return np.array(vectors)\n",
    "\n",
    "\n",
    "# convert datasets to binary and frequency bag of words representations\n",
    "imdb_training_binary_bow_data = generate_binary_bag_of_words_representation(imdb_top_words, imdb_training_data)\n",
    "imdb_validation_binary_bow_data = generate_binary_bag_of_words_representation(imdb_top_words, imdb_validation_data)\n",
    "imdb_test_binary_bow_data = generate_binary_bag_of_words_representation(imdb_top_words, imdb_test_data)\n",
    "imdb_training_frequency_bow_data = generate_frequency_bag_of_words_representation(imdb_top_words, imdb_training_data)\n",
    "imdb_validation_frequency_bow_data = generate_frequency_bag_of_words_representation(imdb_top_words, imdb_validation_data)\n",
    "imdb_test_frequency_bow_data = generate_frequency_bag_of_words_representation(imdb_top_words, imdb_test_data)\n",
    "\n",
    "yelp_training_binary_bow_data = generate_binary_bag_of_words_representation(yelp_top_words, yelp_training_data)\n",
    "yelp_validation_binary_bow_data = generate_binary_bag_of_words_representation(yelp_top_words, yelp_validation_data)\n",
    "yelp_test_binary_bow_data = generate_binary_bag_of_words_representation(yelp_top_words, yelp_test_data)\n",
    "yelp_training_frequency_bow_data = generate_frequency_bag_of_words_representation(yelp_top_words, yelp_training_data)\n",
    "yelp_validation_frequency_bow_data = generate_frequency_bag_of_words_representation(yelp_top_words, yelp_validation_data)\n",
    "yelp_test_frequency_bow_data = generate_frequency_bag_of_words_representation(yelp_top_words, yelp_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random classifier performance on yelp training data:  0.19542857142857142\n",
      "Random classifier performance on yelp validation data:  0.21499999999999997\n",
      "Random classifier performance on yelp test data:  0.202\n",
      "Majority classifier performance on yelp training data:  0.3525714285714286\n",
      "Majority classifier performance on yelp validation data:  0.356\n",
      "Majority classifier performance on yelp test data:  0.351\n"
     ]
    }
   ],
   "source": [
    "# Test yelp data set with binary bag of words representation\n",
    "\n",
    "# method calculates and returns the random classifier f1_score performance given the input data classifications\n",
    "# and range of classification values which will be used to generate random classifications\n",
    "def report_random_classifier_performance(data, classification_range):\n",
    "    random_classifications = np.random.choice(classification_range, len(data))\n",
    "    return sklearn.metrics.f1_score(data, random_classifications, average = 'micro')\n",
    "    \n",
    "# method takes as input classification data and returns majority classifier performance in the form of a f1_score\n",
    "def report_majority_class_classifier_performance(data):\n",
    "    # np.bincount returns array of counts for each index value seen in input data\n",
    "    # np.argmax returns the index of the highest count, which results in the majority class\n",
    "    majority_class = np.argmax(np.bincount(data))\n",
    "    majority_classifications = [majority_class] * len(data)\n",
    "    return sklearn.metrics.f1_score(data, majority_classifications, average = 'micro')\n",
    "    \n",
    "def main(): \n",
    "    print('Random classifier performance on yelp training data: ',report_random_classifier_performance(yelp_training_data[1], range(1,6)))\n",
    "    print('Random classifier performance on yelp validation data: ',report_random_classifier_performance(yelp_validation_data[1], range(1,6)))\n",
    "    print('Random classifier performance on yelp test data: ',report_random_classifier_performance(yelp_test_data[1], range(1,6)))\n",
    "    print('Majority classifier performance on yelp training data: ',report_majority_class_classifier_performance(yelp_training_data[1]))\n",
    "    print('Majority classifier performance on yelp validation data: ',report_majority_class_classifier_performance(yelp_validation_data[1]))\n",
    "    print('Majority classifier performance on yelp test data: ',report_majority_class_classifier_performance(yelp_test_data[1]))\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default Bernoulli Naive Bayes classifier F1-measure without no hyperparameters specified: 0.4115\n",
      "The best value of alpha is  0.021181818181818184\n",
      "The F1-measure score on the training data using the best alpha is  0.7397142857142858\n",
      "The F1-measure score on the validation data using the best alpha is  0.421\n",
      "The F1-measure score on the test data using the best alpha is  0.4345\n",
      "Default Decision Trees classifier F1-measure without no hyperparameters specified: 0.351\n",
      "The optimal hyperparameters are criterion = gini , splitter = random ,max_depth = 8.0\n",
      "The F1-measure score on the training data using the best hyperparameters is  0.48128571428571426\n",
      "The F1-measure score on the validation data using the best hyperparameters is  0.405\n",
      "The F1-measure score on the test data using the best hyperparameters is  0.398\n",
      "Default SVM classifier F1-measure without no hyperparameters specified: 0.4465\n",
      "The optimal hyperparameters are C = 0.001 , tolerance = 1e-09\n",
      "The F1-measure score on the training data using the best hyperparameters is  0.648\n",
      "The F1-measure score on the validation data using the best hyperparameters is  0.494\n",
      "The F1-measure score on the test data using the best hyperparameters is  0.499\n"
     ]
    }
   ],
   "source": [
    "# method trains Bernoulli Naive Bayes classifier with default hyperparameters on yelp training data, then tests the classifer on test data\n",
    "def train_BNB_classifier_default_yelp_bbow():\n",
    "    bernoulli_nb = sklearn.naive_bayes.BernoulliNB()\n",
    "    bernoulli_nb.fit(yelp_training_binary_bow_data, yelp_training_data[1])\n",
    "    predicted_classifications = bernoulli_nb.predict(yelp_test_binary_bow_data)\n",
    "    \n",
    "    print('Default Bernoulli Naive Bayes classifier F1-measure without no hyperparameters specified:', sklearn.metrics.f1_score(yelp_test_data[1], predicted_classifications, average = 'micro'))\n",
    "\n",
    "# method tunes for optimal hyperparameters for the Bernoulli Naive Bayes classifier using the yelp training and validation data,\n",
    "# then classifies the test data using the trained classifier with the optimal hyperparameters\n",
    "def hypertune_BNB_hyperparameters_yelp_bbow():\n",
    "    alpha_values = np.linspace(0.001, 1, 100)\n",
    "    best_f1 = 0\n",
    "    best_alpha = 0\n",
    "    \n",
    "    for a in alpha_values:\n",
    "        bernoulli_nb = sklearn.naive_bayes.BernoulliNB(alpha = a)\n",
    "        bernoulli_nb.fit(yelp_training_binary_bow_data, yelp_training_data[1])\n",
    "        predicted_classifications = bernoulli_nb.predict(yelp_validation_binary_bow_data)\n",
    "        current_f1 = sklearn.metrics.f1_score(yelp_validation_data[1], predicted_classifications, average = 'micro')\n",
    "        \n",
    "        if(current_f1 > best_f1):\n",
    "            best_f1 = current_f1\n",
    "            best_alpha = a\n",
    "            \n",
    "    print('The best value of alpha is ', best_alpha)\n",
    "    \n",
    "    bernoulli_nb = sklearn.naive_bayes.BernoulliNB(alpha = best_alpha)\n",
    "    bernoulli_nb.fit(yelp_training_binary_bow_data, yelp_training_data[1])\n",
    "    \n",
    "    predicted_classifications = bernoulli_nb.predict(yelp_training_binary_bow_data)\n",
    "    print(\"The F1-measure score on the training data using the best alpha is \", sklearn.metrics.f1_score(yelp_training_data[1], predicted_classifications, average = 'micro'))\n",
    "    predicted_classifications = bernoulli_nb.predict(yelp_validation_binary_bow_data)\n",
    "    print(\"The F1-measure score on the validation data using the best alpha is \", sklearn.metrics.f1_score(yelp_validation_data[1], predicted_classifications, average = 'micro'))\n",
    "    predicted_classifications = bernoulli_nb.predict(yelp_test_binary_bow_data)\n",
    "    print(\"The F1-measure score on the test data using the best alpha is \", sklearn.metrics.f1_score(yelp_test_data[1], predicted_classifications, average = 'micro'))\n",
    "    \n",
    "# method trains Decision Tree classifier with default hyperparameters specified on yelp training data, then tests the classifer on test data\n",
    "def train_decision_tree_default_yelp_bbow():\n",
    "    decision_tree = sklearn.tree.DecisionTreeClassifier()\n",
    "    decision_tree.fit(yelp_training_binary_bow_data, yelp_training_data[1])\n",
    "    predicted_classifications = decision_tree.predict(yelp_test_binary_bow_data)\n",
    "    print('Default Decision Trees classifier F1-measure without no hyperparameters specified:', sklearn.metrics.f1_score(yelp_test_data[1], predicted_classifications, average = 'micro'))\n",
    "    \n",
    "# method tunes for optimal hyperparameters for the Decision Trees classifier using the yelp training and validation data,\n",
    "# then classifies the test data using the trained classifier with the optimal hyperparameters\n",
    "def hypertune_decision_tree_hyperparameters_yelp_bbow():\n",
    "    # only tune using hyperparameters seen in class\n",
    "    criterions = ['gini', 'entropy']\n",
    "    splitters = ['best', 'random']\n",
    "    max_depths = np.linspace(6,15,10)\n",
    "    best_f1 = 0\n",
    "    best_hyperparameters = []\n",
    "    \n",
    "    for max_depth in max_depths:\n",
    "        for criterion in criterions:\n",
    "            for splitter in splitters:\n",
    "                decision_tree = sklearn.tree.DecisionTreeClassifier(criterion = criterion, splitter = splitter, max_depth = max_depth)\n",
    "                decision_tree.fit(yelp_training_binary_bow_data, yelp_training_data[1])\n",
    "                predicted_classifications = decision_tree.predict(yelp_validation_binary_bow_data)\n",
    "                current_f1 = sklearn.metrics.f1_score(yelp_validation_data[1], predicted_classifications, average = 'micro')\n",
    "\n",
    "                if current_f1 > best_f1:\n",
    "                    best_f1 = current_f1\n",
    "                    best_hyperparameters = [criterion, splitter, max_depth]\n",
    "\n",
    "    print('The optimal hyperparameters are criterion =',best_hyperparameters[0],', splitter =', best_hyperparameters[1], ',max_depth =', best_hyperparameters[2])\n",
    "\n",
    "    decision_tree = sklearn.tree.DecisionTreeClassifier(criterion = best_hyperparameters[0], splitter = best_hyperparameters[1], max_depth = best_hyperparameters[2])\n",
    "    decision_tree.fit(yelp_training_binary_bow_data, yelp_training_data[1])\n",
    "\n",
    "    predicted_classifications = decision_tree.predict(yelp_training_binary_bow_data)\n",
    "    print(\"The F1-measure score on the training data using the best hyperparameters is \", sklearn.metrics.f1_score(yelp_training_data[1], predicted_classifications, average = 'micro'))\n",
    "    predicted_classifications = decision_tree.predict(yelp_validation_binary_bow_data)\n",
    "    print(\"The F1-measure score on the validation data using the best hyperparameters is \", sklearn.metrics.f1_score(yelp_validation_data[1], predicted_classifications, average = 'micro'))\n",
    "    predicted_classifications = decision_tree.predict(yelp_test_binary_bow_data)\n",
    "    print(\"The F1-measure score on the test data using the best hyperparameters is \", sklearn.metrics.f1_score(yelp_test_data[1], predicted_classifications, average = 'micro'))\n",
    "  \n",
    "# method trains Decision Tree classifier with default hyperparameterson yelp training data, then tests the classifer on test data\n",
    "def train_SVM_default_yelp_bbow():\n",
    "    svc = sklearn.svm.LinearSVC()\n",
    "    svc.fit(yelp_training_binary_bow_data, yelp_training_data[1])\n",
    "    predicted_classifications = svc.predict(yelp_test_binary_bow_data)\n",
    "    print('Default SVM classifier F1-measure without no hyperparameters specified:', sklearn.metrics.f1_score(yelp_test_data[1], predicted_classifications, average = 'micro'))\n",
    "\n",
    "# method tunes for optimal hyperparameters for the linear Support Vector Machine classifier using the yelp training and validation data,\n",
    "# then classifies the test data using the trained classifier with the optimal hyperparameters\n",
    "def hypertune_SVM_hyperparameters_yelp_bbow():\n",
    "    C = np.linspace(0.001, 10, 5)\n",
    "    tolerances = np.linspace(1e-9, 1e-5, 5)\n",
    "    best_f1 = 0\n",
    "    best_hyperparameters = []\n",
    "\n",
    "    for c in C:\n",
    "        for tol in tolerances:\n",
    "            svc = sklearn.svm.LinearSVC(C = c, tol = tol)\n",
    "            svc.fit(yelp_training_binary_bow_data, yelp_training_data[1])\n",
    "            predicted_classifications = svc.predict(yelp_validation_binary_bow_data)\n",
    "            current_f1 = sklearn.metrics.f1_score(yelp_validation_data[1], predicted_classifications, average = 'micro')\n",
    "\n",
    "            if current_f1 > best_f1:\n",
    "                best_f1 = current_f1\n",
    "                best_hyperparameters = [c, tol]\n",
    "                    \n",
    "    \n",
    "    print('The optimal hyperparameters are C =',best_hyperparameters[0],', tolerance =', best_hyperparameters[1])\n",
    "    \n",
    "    svc = sklearn.svm.LinearSVC(C = best_hyperparameters[0], tol = best_hyperparameters[1])\n",
    "        \n",
    "    svc.fit(yelp_training_binary_bow_data, yelp_training_data[1])\n",
    "    predicted_classifications = svc.predict(yelp_training_binary_bow_data) \n",
    "    print(\"The F1-measure score on the training data using the best hyperparameters is \", sklearn.metrics.f1_score(yelp_training_data[1], predicted_classifications, average = 'micro'))\n",
    "\n",
    "    predicted_classifications = svc.predict(yelp_validation_binary_bow_data)  \n",
    "    print(\"The F1-measure score on the validation data using the best hyperparameters is \", sklearn.metrics.f1_score(yelp_validation_data[1], predicted_classifications, average = 'micro'))\n",
    "    \n",
    "    predicted_classifications = svc.predict(yelp_test_binary_bow_data)  \n",
    "    print(\"The F1-measure score on the test data using the best hyperparameters is \", sklearn.metrics.f1_score(yelp_test_data[1], predicted_classifications, average = 'micro'))\n",
    "    \n",
    "def main():\n",
    "    warnings.filterwarnings(\"ignore\")  \n",
    "    train_BNB_classifier_default_yelp_bbow()\n",
    "    hypertune_BNB_hyperparameters_yelp_bbow()\n",
    "    train_decision_tree_default_yelp_bbow()\n",
    "    hypertune_decision_tree_hyperparameters_yelp_bbow()\n",
    "    train_SVM_default_yelp_bbow()\n",
    "    hypertune_SVM_hyperparameters_yelp_bbow()\n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default Gaussian Naive Bayes classifier F1-measure without no hyperparameters specified: 0.302\n",
      "The best value of the smoothing variable is  1.0816326530612246\n",
      "The F1-measure score on the training data using the best smoothing variable is  0.37457142857142856\n",
      "The F1-measure score on the validation data using the best smoothing variable is  0.37\n",
      "The F1-measure score on the test data using the best smoothing value is  0.3605\n",
      "Default Decision Trees classifier F1-measure without no hyperparameters specified: 0.346\n",
      "The optimal hyperparameters are criterion = gini , splitter = best ,max_depth = 11.0\n",
      "The F1-measure score on the training data using the best hyperparameters is  0.5775714285714286\n",
      "The F1-measure score on the validation data using the best hyperparameters is  0.413\n",
      "The F1-measure score on the test data using the best hyperparameters is  0.3855\n",
      "Default SVM classifier F1-measure without no hyperparameters specified: 0.461\n",
      "The optimal hyperparameters are C = 6.667000000000001 , tolerance = 1e-09\n",
      "The F1-measure score on the training data using the best hyperparameters is  0.6308571428571429\n",
      "The F1-measure score on the validation data using the best hyperparameters is  0.501\n",
      "The F1-measure score on the test data using the best hyperparameters is  0.4985\n"
     ]
    }
   ],
   "source": [
    "#Test Yelp data with Frequency bag of words representation\n",
    "\n",
    "# method trains Gaussian naive bayes classifier with default hyperparameters on yelp training data, then tests the classifer on test data\n",
    "def train_GNB_classifier_default_yelp_fbow():\n",
    "    gaussian_nb = sklearn.naive_bayes.GaussianNB()\n",
    "    gaussian_nb.fit(yelp_training_frequency_bow_data, yelp_training_data[1])\n",
    "    predicted_classifications = gaussian_nb.predict(yelp_test_frequency_bow_data)\n",
    "    \n",
    "    print('Default Gaussian Naive Bayes classifier F1-measure without no hyperparameters specified:', sklearn.metrics.f1_score(yelp_test_data[1], predicted_classifications, average = 'micro'))\n",
    "\n",
    "def hypertune_GNB_hyperparameters_yelp_fbow():\n",
    "    smoothing_values = np.linspace(1, 5, 50)\n",
    "    best_f1 = 0\n",
    "    best_smoothing = 0\n",
    "    \n",
    "    for a in smoothing_values:\n",
    "        gaussian_nb = sklearn.naive_bayes.GaussianNB(var_smoothing = a)\n",
    "        gaussian_nb.fit(yelp_training_frequency_bow_data, yelp_training_data[1])\n",
    "        predicted_classifications = gaussian_nb.predict(yelp_validation_frequency_bow_data)\n",
    "        current_f1 = sklearn.metrics.f1_score(yelp_validation_data[1], predicted_classifications, average = 'micro')\n",
    "        \n",
    "        if(current_f1 > best_f1):\n",
    "            best_f1 = current_f1\n",
    "            best_smoothing = a\n",
    "            \n",
    "    print('The best value of the smoothing variable is ', best_smoothing)\n",
    "    \n",
    "    gaussian_nb = sklearn.naive_bayes.GaussianNB(var_smoothing = best_smoothing)\n",
    "    gaussian_nb.fit(yelp_training_frequency_bow_data, yelp_training_data[1])\n",
    "    \n",
    "    predicted_classifications = gaussian_nb.predict(yelp_training_frequency_bow_data)\n",
    "    print(\"The F1-measure score on the training data using the best smoothing variable is \", sklearn.metrics.f1_score(yelp_training_data[1], predicted_classifications, average = 'micro'))\n",
    "    predicted_classifications = gaussian_nb.predict(yelp_validation_frequency_bow_data)\n",
    "    print(\"The F1-measure score on the validation data using the best smoothing variable is \", sklearn.metrics.f1_score(yelp_validation_data[1], predicted_classifications, average = 'micro'))\n",
    "    predicted_classifications = gaussian_nb.predict(yelp_test_frequency_bow_data)\n",
    "    print(\"The F1-measure score on the test data using the best smoothing value is \", sklearn.metrics.f1_score(yelp_test_data[1], predicted_classifications, average = 'micro'))\n",
    "  \n",
    "def train_decision_tree_default_yelp_fbow():\n",
    "    decision_tree = sklearn.tree.DecisionTreeClassifier()\n",
    "    decision_tree.fit(yelp_training_frequency_bow_data, yelp_training_data[1])\n",
    "    predicted_classifications = decision_tree.predict(yelp_test_frequency_bow_data)\n",
    "    print('Default Decision Trees classifier F1-measure without no hyperparameters specified:', sklearn.metrics.f1_score(yelp_test_data[1], predicted_classifications, average = 'micro'))\n",
    "    \n",
    "def hypertune_decision_tree_hyperparameters_yelp_fbow():\n",
    "    # only tune using hyperparameters seen in class\n",
    "    criterions = ['gini', 'entropy']\n",
    "    splitters = ['best', 'random']\n",
    "    max_depths = np.linspace(6, 15, 10)\n",
    "    best_f1 = 0\n",
    "    best_hyperparameters = []\n",
    "    \n",
    "    for max_depth in max_depths:\n",
    "        for criterion in criterions:\n",
    "            for splitter in splitters:\n",
    "                decision_tree = sklearn.tree.DecisionTreeClassifier(criterion = criterion, splitter = splitter, max_depth = max_depth)\n",
    "                decision_tree.fit(yelp_training_frequency_bow_data, yelp_training_data[1])\n",
    "                predicted_classifications = decision_tree.predict(yelp_validation_frequency_bow_data)\n",
    "                current_f1 = sklearn.metrics.f1_score(yelp_validation_data[1], predicted_classifications, average = 'micro')\n",
    "\n",
    "                if current_f1 > best_f1:\n",
    "                    best_f1 = current_f1\n",
    "                    best_hyperparameters = [criterion, splitter, max_depth]\n",
    "            \n",
    "    print('The optimal hyperparameters are criterion =',best_hyperparameters[0],', splitter =', best_hyperparameters[1], ',max_depth =', best_hyperparameters[2])\n",
    "\n",
    "    decision_tree = sklearn.tree.DecisionTreeClassifier(criterion = best_hyperparameters[0], splitter = best_hyperparameters[1], max_depth = best_hyperparameters[2])\n",
    "    decision_tree.fit(yelp_training_frequency_bow_data, yelp_training_data[1])\n",
    "    \n",
    "    predicted_classifications = decision_tree.predict(yelp_training_frequency_bow_data)\n",
    "    print(\"The F1-measure score on the training data using the best hyperparameters is \", sklearn.metrics.f1_score(yelp_training_data[1], predicted_classifications, average = 'micro'))\n",
    "    predicted_classifications = decision_tree.predict(yelp_validation_frequency_bow_data)\n",
    "    print(\"The F1-measure score on the validation data using the best hyperparameters is \", sklearn.metrics.f1_score(yelp_validation_data[1], predicted_classifications, average = 'micro'))\n",
    "    predicted_classifications = decision_tree.predict(yelp_test_frequency_bow_data)\n",
    "    print(\"The F1-measure score on the test data using the best hyperparameters is \", sklearn.metrics.f1_score(yelp_test_data[1], predicted_classifications, average = 'micro'))\n",
    "    \n",
    "def train_SVM_default_yelp_fbow():\n",
    "    svc = sklearn.svm.LinearSVC()\n",
    "    svc.fit(yelp_training_frequency_bow_data, yelp_training_data[1])\n",
    "    predicted_classifications = svc.predict(yelp_test_frequency_bow_data)\n",
    "    print('Default SVM classifier F1-measure without no hyperparameters specified:', sklearn.metrics.f1_score(yelp_test_data[1], predicted_classifications, average = 'micro'))\n",
    "\n",
    "def hypertune_SVM_hyperparameters_yelp_fbow():\n",
    "    C = np.linspace(0.001, 10, 10)\n",
    "    tolerances = np.linspace(1e-9, 1e-5, 5)\n",
    "    best_f1 = 0\n",
    "    best_hyperparameters = []\n",
    "\n",
    "    for c in C:\n",
    "        for tol in tolerances:\n",
    "            svc = sklearn.svm.LinearSVC(C = c, tol = tol)\n",
    "            svc.fit(yelp_training_frequency_bow_data, yelp_training_data[1])\n",
    "            predicted_classifications = svc.predict(yelp_validation_frequency_bow_data)\n",
    "            current_f1 = sklearn.metrics.f1_score(yelp_validation_data[1], predicted_classifications, average = 'micro')\n",
    "\n",
    "            if current_f1 > best_f1:\n",
    "                best_f1 = current_f1\n",
    "                best_hyperparameters = [c, tol]\n",
    "                    \n",
    "    \n",
    "    print('The optimal hyperparameters are C =',best_hyperparameters[0],', tolerance =', best_hyperparameters[1])\n",
    "    \n",
    "    svc = sklearn.svm.LinearSVC(C = best_hyperparameters[0], tol = best_hyperparameters[1])\n",
    "        \n",
    "    svc.fit(yelp_training_frequency_bow_data, yelp_training_data[1])\n",
    "    \n",
    "    predicted_classifications = svc.predict(yelp_training_frequency_bow_data)\n",
    "    print(\"The F1-measure score on the training data using the best hyperparameters is \", sklearn.metrics.f1_score(yelp_training_data[1], predicted_classifications, average = 'micro'))\n",
    "    predicted_classifications = svc.predict(yelp_validation_frequency_bow_data)\n",
    "    print(\"The F1-measure score on the validation data using the best hyperparameters is \", sklearn.metrics.f1_score(yelp_validation_data[1], predicted_classifications, average = 'micro'))\n",
    "    predicted_classifications = svc.predict(yelp_test_frequency_bow_data)\n",
    "    print(\"The F1-measure score on the test data using the best hyperparameters is \", sklearn.metrics.f1_score(yelp_test_data[1], predicted_classifications, average = 'micro'))\n",
    "    \n",
    "def main():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    train_GNB_classifier_default_yelp_fbow() \n",
    "    hypertune_GNB_hyperparameters_yelp_fbow()\n",
    "    train_decision_tree_default_yelp_fbow()\n",
    "    hypertune_decision_tree_hyperparameters_yelp_fbow()\n",
    "    train_SVM_default_yelp_fbow()\n",
    "    hypertune_SVM_hyperparameters_yelp_fbow()\n",
    "        \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random classifier performance on IMDB training data:  0.5012\n",
      "Random classifier performance on IMDB validation data:  0.5012\n",
      "Random classifier performance on IMDB test data:  0.50376\n",
      "Majority classifier performance on IMDB training data:  0.5\n",
      "Majority classifier performance on IMDB validation data:  0.5\n",
      "Majority classifier performance on IMDB test data:  0.5\n"
     ]
    }
   ],
   "source": [
    "# Test IMDB data set with binary bag of words representation\n",
    "# Random classifier\n",
    "\n",
    "# method calculates and returns the random classifier f1_score performance given the input data classifications\n",
    "# and range of classification values which will be used to generate random classifications\n",
    "def report_random_classifier_performance(data, classification_range):\n",
    "    random_classifications = np.random.choice(classification_range, len(data))\n",
    "    return sklearn.metrics.f1_score(data, random_classifications, average = 'micro')\n",
    "    \n",
    "# method takes as input classification data and returns majority classifier performance in the form of a f1_score\n",
    "def report_majority_class_classifier_performance(data):\n",
    "    # np.bincount returns array of counts for each index value seen in input data\n",
    "    # np.argmax returns the index of the highest count, which results in the majority class\n",
    "    majority_class = np.argmax(np.bincount(data))\n",
    "    majority_classifications = [majority_class] * len(data)\n",
    "    return sklearn.metrics.f1_score(data, majority_classifications, average = 'micro')\n",
    "    \n",
    "def main(): \n",
    "    print('Random classifier performance on IMDB training data: ',report_random_classifier_performance(imdb_training_data[1], range(0,2)))\n",
    "    print('Random classifier performance on IMDB validation data: ',report_random_classifier_performance(imdb_validation_data[1], range(0,2)))\n",
    "    print('Random classifier performance on IMDB test data: ',report_random_classifier_performance(imdb_test_data[1], range(0,2)))\n",
    "    print('Majority classifier performance on IMDB training data: ',report_majority_class_classifier_performance(imdb_training_data[1]))\n",
    "    print('Majority classifier performance on IMDB validation data: ',report_majority_class_classifier_performance(imdb_validation_data[1]))\n",
    "    print('Majority classifier performance on IMDB test data: ',report_majority_class_classifier_performance(imdb_test_data[1]))\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default Bernoulli Naive Bayes classifier F1-measure without no hyperparameters specified: 0.8368400000000001\n",
      "The best value of alpha is  0.28354545454545454\n",
      "The F1-measure score on the training data using the best alpha is  0.8729333333333333\n",
      "The F1-measure score on the validation data using the best alpha is  0.8457\n",
      "The F1-measure score on the test data using the best alpha is  0.8366\n",
      "Default Decision Trees classifier F1-measure without no hyperparameters specified: 0.69528\n",
      "The optimal hyperparameters are criterion = gini , splitter = best , max_depth = 16.0\n",
      "The F1-measure score on the training data using the best hyperparameters is  0.8388666666666666\n",
      "The F1-measure score on the validation data using the best hyperparameters is  0.7205999999999999\n",
      "The F1-measure score on the test data using the best hyperparameters  is  0.72456\n",
      "Default SVM classifier F1-measure without no hyperparameters specified: 0.83632\n",
      "The optimal hyperparameters are C = 0.001 , tolerance = 1e-09\n",
      "The F1-measure score on the training data using the best hyperparameters is  0.9070666666666667\n",
      "The F1-measure score on the validation data using the best hyperparameters is  0.8704\n",
      "The F1-measure score on the test data using the best hyperparameters is  0.87064\n"
     ]
    }
   ],
   "source": [
    "# method trains Bernoulli Naive Bayes classifier with default hyperparameters on imdb training data, then tests the classifer on test data\n",
    "def train_BNB_classifier_default_imdb_bbow():\n",
    "    bernoulli_nb = sklearn.naive_bayes.BernoulliNB()\n",
    "    bernoulli_nb.fit(imdb_training_binary_bow_data, imdb_training_data[1])\n",
    "    predicted_classifications = bernoulli_nb.predict(imdb_test_binary_bow_data)\n",
    "    \n",
    "    print('Default Bernoulli Naive Bayes classifier F1-measure without no hyperparameters specified:', sklearn.metrics.f1_score(imdb_test_data[1], predicted_classifications, average = 'micro'))\n",
    "\n",
    "def hypertune_BNB_hyperparameters_imdb_bbow():\n",
    "    alpha_values = np.linspace(0.001, 1, 100)\n",
    "    best_f1 = 0\n",
    "    best_alpha = 0\n",
    "    \n",
    "    for a in alpha_values:\n",
    "        bernoulli_nb = sklearn.naive_bayes.BernoulliNB(alpha = a)\n",
    "        bernoulli_nb.fit(imdb_training_binary_bow_data, imdb_training_data[1])\n",
    "        predicted_classifications = bernoulli_nb.predict(imdb_validation_binary_bow_data)\n",
    "        current_f1 = sklearn.metrics.f1_score(imdb_validation_data[1], predicted_classifications, average = 'micro')\n",
    "        \n",
    "        if(current_f1 > best_f1):\n",
    "            best_f1 = current_f1\n",
    "            best_alpha = a\n",
    "            \n",
    "    print('The best value of alpha is ', best_alpha)\n",
    "    \n",
    "    bernoulli_nb = sklearn.naive_bayes.BernoulliNB(alpha = best_alpha)\n",
    "    bernoulli_nb.fit(imdb_training_binary_bow_data, imdb_training_data[1])\n",
    "    \n",
    "    predicted_classifications = bernoulli_nb.predict(imdb_training_binary_bow_data)\n",
    "    print(\"The F1-measure score on the training data using the best alpha is \", sklearn.metrics.f1_score(imdb_training_data[1], predicted_classifications, average = 'micro'))\n",
    "    predicted_classifications = bernoulli_nb.predict(imdb_validation_binary_bow_data)\n",
    "    print(\"The F1-measure score on the validation data using the best alpha is \", sklearn.metrics.f1_score(imdb_validation_data[1], predicted_classifications, average = 'micro'))\n",
    "    predicted_classifications = bernoulli_nb.predict(imdb_test_binary_bow_data)\n",
    "    print(\"The F1-measure score on the test data using the best alpha is \", sklearn.metrics.f1_score(imdb_test_data[1], predicted_classifications, average = 'micro'))\n",
    "    \n",
    "def train_decision_tree_default_imdb_bbow():\n",
    "    decision_tree = sklearn.tree.DecisionTreeClassifier()\n",
    "    decision_tree.fit(imdb_training_binary_bow_data, imdb_training_data[1])\n",
    "    predicted_classifications = decision_tree.predict(imdb_test_binary_bow_data)\n",
    "    print('Default Decision Trees classifier F1-measure without no hyperparameters specified:', sklearn.metrics.f1_score(imdb_test_data[1], predicted_classifications, average = 'micro'))\n",
    "    \n",
    "def hypertune_decision_tree_hyperparameters_imdb_bbow():\n",
    "    criterions = ['gini', 'entropy']\n",
    "    splitters = ['best', 'random']\n",
    "    max_depths = np.linspace(10, 20, 10)\n",
    "    best_f1 = 0\n",
    "    best_hyperparameters = []\n",
    "    \n",
    "    for max_depth in max_depths:  \n",
    "        for criterion in criterions:\n",
    "            for splitter in splitters:\n",
    "                decision_tree = sklearn.tree.DecisionTreeClassifier(criterion = criterion, splitter = splitter, max_depth = max_depth)\n",
    "                decision_tree.fit(imdb_training_binary_bow_data, imdb_training_data[1])\n",
    "                predicted_classifications = decision_tree.predict(imdb_validation_binary_bow_data)\n",
    "                current_f1 = sklearn.metrics.f1_score(imdb_validation_data[1], predicted_classifications, average = 'micro')\n",
    "\n",
    "                if current_f1 > best_f1:\n",
    "                    best_f1 = current_f1\n",
    "                    best_hyperparameters = [criterion, splitter, max_depth]\n",
    "            \n",
    "    print('The optimal hyperparameters are criterion =',best_hyperparameters[0],', splitter =', best_hyperparameters[1], ', max_depth =', best_hyperparameters[2])\n",
    "\n",
    "    decision_tree = sklearn.tree.DecisionTreeClassifier(criterion = best_hyperparameters[0], splitter = best_hyperparameters[1], max_depth = best_hyperparameters[2])\n",
    "    decision_tree.fit(imdb_training_binary_bow_data, imdb_training_data[1])\n",
    "    \n",
    "    predicted_classifications = decision_tree.predict(imdb_training_binary_bow_data)\n",
    "    print(\"The F1-measure score on the training data using the best hyperparameters is \", sklearn.metrics.f1_score(imdb_training_data[1], predicted_classifications, average = 'micro'))\n",
    "    predicted_classifications = decision_tree.predict(imdb_validation_binary_bow_data)\n",
    "    print(\"The F1-measure score on the validation data using the best hyperparameters is \", sklearn.metrics.f1_score(imdb_validation_data[1], predicted_classifications, average = 'micro'))\n",
    "    predicted_classifications = decision_tree.predict(imdb_test_binary_bow_data)\n",
    "    print(\"The F1-measure score on the test data using the best hyperparameters  is \", sklearn.metrics.f1_score(imdb_test_data[1], predicted_classifications, average = 'micro'))\n",
    "  \n",
    "def train_SVM_default_imdb_bbow():\n",
    "    svc = sklearn.svm.LinearSVC()\n",
    "    svc.fit(imdb_training_binary_bow_data, imdb_training_data[1])\n",
    "    predicted_classifications = svc.predict(imdb_test_binary_bow_data)\n",
    "    print('Default SVM classifier F1-measure without no hyperparameters specified:', sklearn.metrics.f1_score(imdb_test_data[1], predicted_classifications, average = 'micro'))\n",
    "\n",
    "def hypertune_SVM_hyperparameters_imdb_bbow():\n",
    "    C = np.linspace(1e-3, 10, 10)\n",
    "    tolerances = np.linspace(1e-9, 1e-5, 5)\n",
    "    best_f1 = 0\n",
    "    best_hyperparameters = []\n",
    "\n",
    "    for c in C:\n",
    "        for tol in tolerances:\n",
    "            svc = sklearn.svm.LinearSVC(C = c, tol = tol)\n",
    "            svc.fit(imdb_training_binary_bow_data, imdb_training_data[1])\n",
    "            predicted_classifications = svc.predict(imdb_validation_binary_bow_data)\n",
    "            current_f1 = sklearn.metrics.f1_score(imdb_validation_data[1], predicted_classifications, average = 'micro')\n",
    "\n",
    "            if current_f1 > best_f1:\n",
    "                best_f1 = current_f1\n",
    "                best_hyperparameters = [c, tol]\n",
    "                    \n",
    "    \n",
    "    print('The optimal hyperparameters are C =',best_hyperparameters[0],', tolerance =', best_hyperparameters[1])\n",
    "    \n",
    "    svc = sklearn.svm.LinearSVC(C = best_hyperparameters[0], tol = best_hyperparameters[1])\n",
    "        \n",
    "    svc.fit(imdb_training_binary_bow_data, imdb_training_data[1])\n",
    "    \n",
    "    predicted_classifications = svc.predict(imdb_training_binary_bow_data)\n",
    "    print(\"The F1-measure score on the training data using the best hyperparameters is \", sklearn.metrics.f1_score(imdb_training_data[1], predicted_classifications, average = 'micro'))\n",
    "    predicted_classifications = svc.predict(imdb_validation_binary_bow_data)\n",
    "    print(\"The F1-measure score on the validation data using the best hyperparameters is \", sklearn.metrics.f1_score(imdb_validation_data[1], predicted_classifications, average = 'micro'))\n",
    "    predicted_classifications = svc.predict(imdb_test_binary_bow_data)\n",
    "    print(\"The F1-measure score on the test data using the best hyperparameters is \", sklearn.metrics.f1_score(imdb_test_data[1], predicted_classifications, average = 'micro'))\n",
    "    \n",
    "def main():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    \n",
    "    train_BNB_classifier_default_imdb_bbow()\n",
    "    hypertune_BNB_hyperparameters_imdb_bbow()\n",
    "    train_decision_tree_default_imdb_bbow()\n",
    "    hypertune_decision_tree_hyperparameters_imdb_bbow()\n",
    "    train_SVM_default_imdb_bbow()\n",
    "    hypertune_SVM_hyperparameters_imdb_bbow()\n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default Gaussian Naive Bayes classifier F1-measure without no hyperparameters specified: 0.69824\n",
      "The best value of var_smoothing is  6.939081632653061e-10\n",
      "The F1-measure score on the training data using the best smoothing value is  0.8628\n",
      "The F1-measure score on the validation data using the best smoothing value is  0.7607999999999999\n",
      "The F1-measure score on the test data using the best smoothing value is  0.6978\n",
      "Default Decision Trees classifier F1-measure without no hyperparameters specified: 0.69832\n",
      "The optimal hyperparameters are criterion = gini , splitter = random , max_depth = 18.0\n",
      "The F1-measure score on the training data using the best hyperparameters is  0.8202666666666667\n",
      "The F1-measure score on the validation data using the best hyperparameters is  0.7192\n",
      "The F1-measure score on the test data using the best hyperparameters is  0.72216\n",
      "Default SVM classifier F1-measure without no hyperparameters specified: 0.79332\n",
      "The optimal hyperparameters are C = 20.0 , tolerance = 1e-09\n",
      "The F1-measure score on the training data using the best hyperparameters is  0.9084666666666666\n",
      "The F1-measure score on the validation data using the best hyperparameters is  0.8713\n",
      "The F1-measure score on the test data using the best hyperparameters is  0.8695999999999999\n"
     ]
    }
   ],
   "source": [
    "#Test imdb data with Frequency bag of words representation\n",
    "\n",
    "def train_GNB_classifier_default_imdb_fbow():\n",
    "    gaussian_nb = sklearn.naive_bayes.GaussianNB()\n",
    "    gaussian_nb.fit(imdb_training_frequency_bow_data, imdb_training_data[1])\n",
    "    predicted_classifications = gaussian_nb.predict(imdb_test_frequency_bow_data)\n",
    "    \n",
    "    print('Default Gaussian Naive Bayes classifier F1-measure without no hyperparameters specified:', sklearn.metrics.f1_score(imdb_test_data[1], predicted_classifications, average = 'micro'))\n",
    "\n",
    "def hypertune_GNB_hyperparameters_imdb_fbow():\n",
    "    smoothing_values = np.linspace(1e-13, 1e-9, 50)\n",
    "    best_f1 = 0\n",
    "    best_smoothing = 0\n",
    "    \n",
    "    for a in smoothing_values:\n",
    "        gaussian_nb = sklearn.naive_bayes.GaussianNB(var_smoothing = a)\n",
    "        gaussian_nb.fit(imdb_training_frequency_bow_data, imdb_training_data[1])\n",
    "        predicted_classifications = gaussian_nb.predict(imdb_validation_frequency_bow_data)\n",
    "        current_f1 = sklearn.metrics.f1_score(imdb_validation_data[1], predicted_classifications, average = 'micro')\n",
    "        \n",
    "        if(current_f1 > best_f1):\n",
    "            best_f1 = current_f1\n",
    "            best_smoothing = a\n",
    "            \n",
    "    print('The best value of var_smoothing is ', best_smoothing)\n",
    "    \n",
    "    gaussian_nb = sklearn.naive_bayes.GaussianNB(var_smoothing = best_smoothing)\n",
    "    gaussian_nb.fit(imdb_training_frequency_bow_data, imdb_training_data[1])\n",
    "    \n",
    "    predicted_classifications = gaussian_nb.predict(imdb_training_frequency_bow_data)\n",
    "    print(\"The F1-measure score on the training data using the best smoothing value is \", sklearn.metrics.f1_score(imdb_training_data[1], predicted_classifications, average = 'micro'))\n",
    "    predicted_classifications = gaussian_nb.predict(imdb_validation_frequency_bow_data)\n",
    "    print(\"The F1-measure score on the validation data using the best smoothing value is \", sklearn.metrics.f1_score(imdb_validation_data[1], predicted_classifications, average = 'micro'))\n",
    "    predicted_classifications = gaussian_nb.predict(imdb_test_frequency_bow_data)\n",
    "    print(\"The F1-measure score on the test data using the best smoothing value is \", sklearn.metrics.f1_score(imdb_test_data[1], predicted_classifications, average = 'micro'))\n",
    "  \n",
    "def train_decision_tree_default_imdb_fbow():\n",
    "    decision_tree = sklearn.tree.DecisionTreeClassifier()\n",
    "    decision_tree.fit(imdb_training_frequency_bow_data, imdb_training_data[1])\n",
    "    predicted_classifications = decision_tree.predict(imdb_test_frequency_bow_data)\n",
    "    print('Default Decision Trees classifier F1-measure without no hyperparameters specified:', sklearn.metrics.f1_score(imdb_test_data[1], predicted_classifications, average = 'micro'))\n",
    "    \n",
    "def hypertune_decision_tree_hyperparameters_imdb_fbow():\n",
    "    # only tune using hyperparameters seen in class\n",
    "    criterions = ['gini', 'entropy']\n",
    "    splitters = ['best', 'random']\n",
    "    max_depths = np.linspace(10, 20, 10)\n",
    "    best_f1 = 0\n",
    "    best_hyperparameters = []\n",
    "    \n",
    "    for max_depth in max_depths: \n",
    "        for criterion in criterions:\n",
    "            for splitter in splitters:\n",
    "                decision_tree = sklearn.tree.DecisionTreeClassifier(criterion = criterion, splitter = splitter, max_depth = max_depth)\n",
    "                decision_tree.fit(imdb_training_frequency_bow_data, imdb_training_data[1])\n",
    "                predicted_classifications = decision_tree.predict(imdb_validation_frequency_bow_data)\n",
    "                current_f1 = sklearn.metrics.f1_score(imdb_validation_data[1], predicted_classifications, average = 'micro')\n",
    "\n",
    "                if current_f1 > best_f1:\n",
    "                    best_f1 = current_f1\n",
    "                    best_hyperparameters = [criterion, splitter, max_depth]\n",
    "            \n",
    "    print('The optimal hyperparameters are criterion =',best_hyperparameters[0],', splitter =', best_hyperparameters[1], ', max_depth =', best_hyperparameters[2])\n",
    "\n",
    "    decision_tree = sklearn.tree.DecisionTreeClassifier(criterion = best_hyperparameters[0], splitter = best_hyperparameters[1], max_depth = best_hyperparameters[2])\n",
    "    decision_tree.fit(imdb_training_frequency_bow_data, imdb_training_data[1])\n",
    "    \n",
    "    predicted_classifications = decision_tree.predict(imdb_training_frequency_bow_data)\n",
    "    print(\"The F1-measure score on the training data using the best hyperparameters is \", sklearn.metrics.f1_score(imdb_training_data[1], predicted_classifications, average = 'micro'))\n",
    "    predicted_classifications = decision_tree.predict(imdb_validation_frequency_bow_data)\n",
    "    print(\"The F1-measure score on the validation data using the best hyperparameters is \", sklearn.metrics.f1_score(imdb_validation_data[1], predicted_classifications, average = 'micro'))\n",
    "    predicted_classifications = decision_tree.predict(imdb_test_frequency_bow_data)\n",
    "    print(\"The F1-measure score on the test data using the best hyperparameters is \", sklearn.metrics.f1_score(imdb_test_data[1], predicted_classifications, average = 'micro'))\n",
    "    \n",
    "def train_SVM_default_imdb_fbow():\n",
    "    svc = sklearn.svm.LinearSVC()\n",
    "    svc.fit(imdb_training_frequency_bow_data, imdb_training_data[1])\n",
    "    predicted_classifications = svc.predict(imdb_test_frequency_bow_data)\n",
    "    print('Default SVM classifier F1-measure without no hyperparameters specified:', sklearn.metrics.f1_score(imdb_test_data[1], predicted_classifications, average = 'micro'))\n",
    "\n",
    "def hypertune_SVM_hyperparameters_imdb_fbow():\n",
    "    C = np.linspace(10, 20, 10)\n",
    "    tolerances = np.linspace(1e-9, 1e-5, 10)\n",
    "    best_f1 = 0\n",
    "    best_hyperparameters = []\n",
    "\n",
    "    for c in C:\n",
    "        for tol in tolerances:\n",
    "            svc = sklearn.svm.LinearSVC(C = c, tol = tol)\n",
    "            svc.fit(imdb_training_frequency_bow_data, imdb_training_data[1])\n",
    "            predicted_classifications = svc.predict(imdb_validation_frequency_bow_data)\n",
    "            current_f1 = sklearn.metrics.f1_score(imdb_validation_data[1], predicted_classifications, average = 'micro')\n",
    "\n",
    "            if current_f1 > best_f1:\n",
    "                best_f1 = current_f1\n",
    "                best_hyperparameters = [c, tol]\n",
    "                    \n",
    "    \n",
    "    print('The optimal hyperparameters are C =',best_hyperparameters[0],', tolerance =', best_hyperparameters[1])\n",
    "    \n",
    "    svc = sklearn.svm.LinearSVC(C = best_hyperparameters[0], tol = best_hyperparameters[1])\n",
    "        \n",
    "    svc.fit(imdb_training_frequency_bow_data, imdb_training_data[1])\n",
    "    \n",
    "    predicted_classifications = svc.predict(imdb_training_frequency_bow_data)\n",
    "    print(\"The F1-measure score on the training data using the best hyperparameters is \", sklearn.metrics.f1_score(imdb_training_data[1], predicted_classifications, average = 'micro'))\n",
    "    predicted_classifications = svc.predict(imdb_validation_frequency_bow_data)\n",
    "    print(\"The F1-measure score on the validation data using the best hyperparameters is \", sklearn.metrics.f1_score(imdb_validation_data[1], predicted_classifications, average = 'micro'))\n",
    "    predicted_classifications = svc.predict(imdb_test_frequency_bow_data)\n",
    "    print(\"The F1-measure score on the test data using the best hyperparameters is \", sklearn.metrics.f1_score(imdb_test_data[1], predicted_classifications, average = 'micro'))\n",
    "    \n",
    "def main():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    train_GNB_classifier_default_imdb_fbow() \n",
    "    hypertune_GNB_hyperparameters_imdb_fbow()\n",
    "    train_decision_tree_default_imdb_fbow()\n",
    "    hypertune_decision_tree_hyperparameters_imdb_fbow()\n",
    "    train_SVM_default_imdb_fbow()\n",
    "    hypertune_SVM_hyperparameters_imdb_fbow()\n",
    "        \n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
